\section{Limitation in Quiescing}

As discussed in Section~\ref{sec:bg_drive}, the formal verification of XMHF's and its hypapp's memory integrity requires all intercept handlers to run in a single-threaded environment. The XMHF design achieves atomicity of intercept handlers through quiescing: when any CPU runs an intercept handler, all other CPUs are quiesced.

However, we find an implementation limitation in XMHF version 6.1.0. Specifically, XMHF does not achieve atomicity by quiescing all other CPUs during intercept handlers. Instead, it uses two strategies to prevent race conditions between CPUs. First, when the intercept handler calls the hypapp callback function, XMHF quiesces all other CPUs. This prevents race conditions when the hypapp callback function concurrently accesses shared states on multiple CPUs. Second, XMHF uses a spin lock to protect the printf function from concurrent access. This prevents race conditions when multiple CPUs print debug messages at the same time. Since other states and resources accessed by the intercept handler are specific to the current CPU, race conditions do not occur in these cases.

In \XMHF64, we temporarily inherit this implementation limitation from XMHF. The \XMHF64 intercept handler quiesces all other CPUs before calling hypapp callback functions. \XMHF64 uses spin locks and read-write locks to prevent race conditions when the intercept handler accesses states and resources shared between CPUs. Other states and resources accessed by the intercept handler are specific to the current CPU, where race conditions do not occur.

We argue that this is only a limitation in the current implementation of \XMHF64. All \XMHF64 intercept handlers can run without interaction with other CPUs, so it is relatively easy to modify the \XMHF64 implementation to quiesce all other CPUs when any intercept handler is running. On modern hardware, we only expect a minor decrease in performance. We leave this modification as future work.

